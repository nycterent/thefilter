name: Daily Content Check & Auto Newsletter

on:
  # Run daily at 9:00 AM UTC
  schedule:
    - cron: "0 9 * * *"
  
  # Manual trigger for testing
  workflow_dispatch:
    inputs:
      force_generation:
        description: "Force newsletter generation regardless of article count"
        required: false
        default: "false"
        type: boolean
      debug:
        description: "Enable debug logging"
        required: false
        default: "false"
        type: boolean

jobs:
  check-content:
    runs-on: ubuntu-latest
    environment: production
    
    permissions:
      contents: read
      issues: write
      packages: read
      actions: write  # Need this to trigger other workflows
    
    outputs:
      article_count: ${{ steps.count_articles.outputs.count }}
      should_generate: ${{ steps.count_articles.outputs.should_generate }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
      
      # Restore cache from previous runs to avoid rate limiting
      - name: Restore Readwise cache
        uses: actions/cache@v4
        with:
          path: .cache/
          key: readwise-cache-daily-${{ github.run_id }}
          restore-keys: |
            readwise-cache-daily-
            readwise-cache-
      
      - name: Check twiar article count with cache fallback
        id: count_articles
        run: |
          echo "üîç Checking twiar-tagged articles with cache fallback..."
          
          # Create enhanced script with cache fallback and retry logic
          cat > count_twiar.py << 'EOF'
          import asyncio
          import sys
          import os
          from src.clients.readwise import ReadwiseClient
          from src.core.readwise_cache import get_readwise_cache
          from src.models.settings import Settings
          
          async def count_twiar_articles():
              try:
                  settings = Settings()
                  if not settings.readwise_api_key:
                      print("‚ùå Readwise API key not found")
                      return 0
                  
                  # First, try to get from cache
                  cache = get_readwise_cache()
                  cached_docs = cache.get_cached_documents(days=30)
                  
                  if cached_docs is not None:
                      count = len(cached_docs)
                      print(f"üìä Using cached data: {count} twiar-tagged articles (cache hit)")
                      data_source = "cache"
                  else:
                      # Try API with retry logic
                      print("üíæ Cache miss - fetching from Readwise API...")
                      client = ReadwiseClient(settings.readwise_api_key)
                      
                      # Retry with exponential backoff
                      max_retries = 2
                      for attempt in range(max_retries):
                          try:
                              documents = await client.get_recent_reader_documents(days=30)
                              count = len(documents)
                              data_source = "api"
                              print(f"üìä API success: {count} twiar-tagged articles (fresh data)")
                              break
                          except Exception as api_error:
                              print(f"‚ö†Ô∏è API attempt {attempt + 1}/{max_retries} failed: {api_error}")
                              if attempt == max_retries - 1:
                                  # Last resort: check for any stale cache
                                  cache_status = cache.get_cache_status()
                                  if cache_status['total_entries'] > 0:
                                      print("üîÑ Using stale cache as fallback")
                                      # Get stale data if available
                                      try:
                                          # Temporarily get expired cache
                                          import sqlite3
                                          from datetime import datetime
                                          with sqlite3.connect(cache.db_path) as conn:
                                              conn.row_factory = sqlite3.Row
                                              cursor = conn.execute("SELECT documents FROM readwise_documents ORDER BY cached_at DESC LIMIT 1")
                                              row = cursor.fetchone()
                                              if row:
                                                  import json
                                                  stale_docs = json.loads(row[0])
                                                  count = len(stale_docs)
                                                  data_source = "stale_cache"
                                                  print(f"üìä Using stale cache: {count} articles (degraded mode)")
                                                  break
                                      except Exception as cache_error:
                                          print(f"Failed to retrieve stale cache: {cache_error}")
                                  
                                  # If all else fails, set to 0 but don't crash
                                  print("üí• All data sources failed - defaulting to 0")
                                  count = 0
                                  data_source = "failed"
                                  break
                              else:
                                  # Wait before retry
                                  wait_time = (attempt + 1) * 15  # 15s, 30s
                                  print(f"‚è≥ Waiting {wait_time}s before retry...")
                                  await asyncio.sleep(wait_time)
                  
                  # Should generate if we have 7+ articles or force flag is set
                  force = os.environ.get('FORCE_GENERATION', 'false').lower() == 'true'
                  should_generate = count >= 7 or force
                  
                  print(f"üéØ Newsletter generation: {'‚úÖ YES' if should_generate else '‚ùå NO'} (threshold: 7, force: {force})")
                  print(f"üìä Data source: {data_source}")
                  
                  # Set GitHub outputs
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write(f"count={count}\n")
                      f.write(f"should_generate={str(should_generate).lower()}\n")
                      f.write(f"data_source={data_source}\n")
                  
                  return count
                  
              except Exception as e:
                  print(f"‚ùå Critical error checking articles: {e}")
                  import traceback
                  traceback.print_exc()
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                      f.write(f"count=0\n")
                      f.write(f"should_generate=false\n")
                      f.write(f"data_source=error\n")
                  return 0
          
          if __name__ == "__main__":
              count = asyncio.run(count_twiar_articles())
              sys.exit(0 if count >= 0 else 1)
          EOF
          
          # Run the enhanced count script
          python count_twiar.py
        env:
          READWISE_API_KEY: ${{ secrets.READWISE_API_KEY }}
          GLASP_API_KEY: ${{ secrets.GLASP_API_KEY }}
          RSS_FEEDS: ${{ secrets.RSS_FEEDS }}
          BUTTONDOWN_API_KEY: ${{ secrets.BUTTONDOWN_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          UNSPLASH_API_KEY: ${{ secrets.UNSPLASH_API_KEY }}
          FORCE_GENERATION: ${{ inputs.force_generation }}
      
      - name: Create status issue
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const articleCount = '${{ steps.count_articles.outputs.count }}';
            const shouldGenerate = '${{ steps.count_articles.outputs.should_generate }}';
            const forceFlag = '${{ inputs.force_generation }}' === 'true';
            
            const statusIcon = shouldGenerate === 'true' ? '‚úÖ' : 'üìä';
            const actionText = shouldGenerate === 'true' ? 'Newsletter will be generated!' : 'Waiting for more content...';
            
            const issueBody = `## ${statusIcon} Daily Content Check - ${new Date().toISOString().split('T')[0]}
            
            **Timestamp:** ${new Date().toISOString()}
            **Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            ### üìä Content Status
            - **Twiar articles found:** ${articleCount}
            - **Data source:** ${{ steps.count_articles.outputs.data_source }}
            - **Threshold required:** 7
            - **Force generation:** ${forceFlag ? 'Yes' : 'No'}
            - **Action:** ${actionText}
            
            ### üìã Next Steps
            ${shouldGenerate === 'true' ? `
            üöÄ **Newsletter generation triggered!**
            - The newsletter workflow will start automatically
            - Check the [Newsletter Generation workflow](${{ github.server_url }}/${{ github.repository }}/actions/workflows/newsletter.yml) for progress
            - You'll receive a separate issue when generation completes
            ` : `
            ‚è≥ **Waiting for more content**
            - Need ${7 - parseInt(articleCount)} more twiar-tagged articles
            - Check will run again tomorrow at 9:00 AM UTC
            - You can manually trigger generation with the force flag if needed
            `}
            
            ### üîó Quick Actions
            - [üîÑ Run Manual Check](${{ github.server_url }}/${{ github.repository }}/actions/workflows/daily-content-check.yml)
            - [üìß Force Newsletter Generation](${{ github.server_url }}/${{ github.repository }}/actions/workflows/newsletter.yml)
            - [üìä All Workflows](${{ github.server_url }}/${{ github.repository }}/actions)
            
            ---
            *Automated content check ‚Ä¢ Next check: tomorrow at 9:00 AM UTC*`;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `${statusIcon} Content Check: ${articleCount} articles (${shouldGenerate === 'true' ? 'GENERATING' : 'waiting'}) - ${new Date().toISOString().split('T')[0]}`,
              body: issueBody,
              labels: ['newsletter', 'automated', 'content-check', shouldGenerate === 'true' ? 'generating' : 'waiting']
            });

  trigger-newsletter:
    needs: check-content
    if: needs.check-content.outputs.should_generate == 'true'
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      issues: write
      actions: write
    
    steps:
      - name: Trigger Newsletter Generation
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('üöÄ Triggering newsletter generation...');
            
            const response = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'newsletter.yml',
              ref: 'main',
              inputs: {
                dry_run: 'false',
                debug: '${{ inputs.debug }}'
              }
            });
            
            console.log('‚úÖ Newsletter generation workflow triggered successfully');
            console.log(`üìß Check progress: ${{ github.server_url }}/${{ github.repository }}/actions/workflows/newsletter.yml`);
      
      - name: Log trigger success
        run: |
          echo "‚úÖ Newsletter generation workflow triggered successfully"
          echo "üìä Monitor progress at: ${{ github.server_url }}/${{ github.repository }}/actions/workflows/newsletter.yml"
          echo "üìß Newsletter generation will create a separate issue when complete"